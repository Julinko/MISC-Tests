{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Benchmarking\n",
    "Based on the ai-benchmark. \"AI Benchmark is an open source python library for evaluating AI performance of various hardware platforms, including CPUs, GPUs and TPUs.\" \n",
    "</br>Quote: https://pypi.org/project/ai-benchmark/ </br> </br> More info and scores here: https://ai-benchmark.com/alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow\n",
    "# %pip install tensorflow-gpu\n",
    "# %pip install ai-benchmark\n",
    "\n",
    "# Libraries\n",
    "from ai_benchmark import AIBenchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>   AI-Benchmark-v.0.1.2   \n",
      ">>   Let the AI Games begin..\n",
      "\n",
      "*  TF Version: 2.9.1\n",
      "*  Platform: Linux-5.15.0-41-generic-x86_64-with-glibc2.35\n",
      "*  CPU: N/A\n",
      "*  CPU RAM: 63 GB\n",
      "*  GPU/0: NVIDIA GeForce RTX 3060\n",
      "*  GPU RAM: 9.5 GB\n",
      "*  CUDA Version: 11.5\n",
      "*  CUDA Build: V11.5.119\n",
      "\n",
      "The benchmark is running...\n",
      "The tests might take up to 20 minutes\n",
      "Please don't interrupt the script\n",
      "\n",
      "1/19. MobileNet-V2\n",
      "\n",
      "1.1 - inference | batch=50, size=224x224: 52.4 ± 5.3 ms\n",
      "1.2 - training  | batch=50, size=224x224: 266 ± 8 ms\n",
      "\n",
      "2/19. Inception-V3\n",
      "\n",
      "2.1 - inference | batch=20, size=346x346: 77.1 ± 5.6 ms\n",
      "2.2 - training  | batch=20, size=346x346: 230 ± 2 ms\n",
      "\n",
      "3/19. Inception-V4\n",
      "\n",
      "3.1 - inference | batch=10, size=346x346: 69.7 ± 1.2 ms\n",
      "3.2 - training  | batch=10, size=346x346: 235 ± 3 ms\n",
      "\n",
      "4/19. Inception-ResNet-V2\n",
      "\n",
      "4.1 - inference | batch=10, size=346x346: 93.6 ± 1.1 ms\n",
      "4.2 - training  | batch=8, size=346x346: 249 ± 3 ms\n",
      "\n",
      "5/19. ResNet-V2-50\n",
      "\n",
      "5.1 - inference | batch=10, size=346x346: 49.0 ± 0.6 ms\n",
      "5.2 - training  | batch=10, size=346x346: 148.5 ± 0.7 ms\n",
      "\n",
      "6/19. ResNet-V2-152\n",
      "\n",
      "6.1 - inference | batch=10, size=256x256: 64.6 ± 0.8 ms\n",
      "6.2 - training  | batch=10, size=256x256: 222 ± 2 ms\n",
      "\n",
      "7/19. VGG-16\n",
      "\n",
      "7.1 - inference | batch=20, size=224x224: 103 ± 1 ms\n",
      "7.2 - training  | batch=2, size=224x224: 132 ± 1 ms\n",
      "\n",
      "8/19. SRCNN 9-5-5\n",
      "\n",
      "8.1 - inference | batch=10, size=512x512: 109 ± 2 ms\n",
      "8.2 - inference | batch=1, size=1536x1536: 83.7 ± 0.5 ms\n",
      "8.3 - training  | batch=10, size=512x512: 255 ± 7 ms\n",
      "\n",
      "9/19. VGG-19 Super-Res\n",
      "\n",
      "9.1 - inference | batch=10, size=256x256: 135 ± 2 ms\n",
      "9.2 - inference | batch=1, size=1024x1024: 214 ± 1 ms\n",
      "9.3 - training  | batch=10, size=224x224: 317 ± 8 ms\n",
      "\n",
      "10/19. ResNet-SRGAN\n",
      "\n",
      "10.1 - inference | batch=10, size=512x512: 160 ± 1 ms\n",
      "10.2 - inference | batch=1, size=1536x1536: 130 ± 7 ms\n",
      "10.3 - training  | batch=5, size=512x512: 197 ± 1 ms\n",
      "\n",
      "11/19. ResNet-DPED\n",
      "\n",
      "11.1 - inference | batch=10, size=256x256: 161.0 ± 0.3 ms\n",
      "11.2 - inference | batch=1, size=1024x1024: 253.3 ± 0.5 ms\n",
      "11.3 - training  | batch=15, size=128x128: 233.5 ± 0.5 ms\n",
      "\n",
      "12/19. U-Net\n",
      "\n",
      "12.1 - inference | batch=4, size=512x512: 285.3 ± 1.0 ms\n",
      "12.2 - inference | batch=1, size=1024x1024: 278.6 ± 0.6 ms\n",
      "12.3 - training  | batch=4, size=256x256: 279.9 ± 0.7 ms\n",
      "\n",
      "13/19. Nvidia-SPADE\n",
      "\n",
      "13.1 - inference | batch=5, size=128x128: 104.3 ± 0.8 ms\n",
      "13.2 - training  | batch=1, size=128x128: 162.6 ± 0.6 ms\n",
      "\n",
      "14/19. ICNet\n",
      "\n",
      "14.1 - inference | batch=5, size=1024x1536: 193 ± 2 ms\n",
      "14.2 - training  | batch=10, size=1024x1536: 555 ± 8 ms\n",
      "\n",
      "15/19. PSPNet\n",
      "\n",
      "15.1 - inference | batch=5, size=720x720: 460 ± 8 ms\n",
      "15.2 - training  | batch=1, size=512x512: 177.9 ± 0.8 ms\n",
      "\n",
      "16/19. DeepLab\n",
      "\n",
      "16.1 - inference | batch=2, size=512x512: 132.9 ± 0.7 ms\n",
      "16.2 - training  | batch=1, size=384x384: 149 ± 1 ms\n",
      "\n",
      "17/19. Pixel-RNN\n",
      "\n",
      "17.1 - inference | batch=50, size=64x64: 507 ± 18 ms\n",
      "17.2 - training  | batch=10, size=64x64: 2071 ± 53 ms\n",
      "\n",
      "18/19. LSTM-Sentiment\n",
      "\n",
      "18.1 - inference | batch=100, size=1024x300: 619 ± 46 ms\n",
      "18.2 - training  | batch=10, size=1024x300: 1072 ± 17 ms\n",
      "\n",
      "19/19. GNMT-Translation\n",
      "\n",
      "19.1 - inference | batch=1, size=1x20: 245 ± 4 ms\n",
      "\n",
      "Device Inference Score: 9438\n",
      "Device Training Score: 10771\n",
      "Device AI Score: 20209\n",
      "\n",
      "For more information and results, please visit http://ai-benchmark.com/alpha\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Benchmark\n",
    "#  Verbose Levels from 0-3: run tests silently | with short summary | with information about each run | with TF logs\n",
    "benchmark = AIBenchmark(use_CPU=False, verbose_level=1)\n",
    "results = benchmark.run(precision=\"normal\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a80952ccc91fe19b202c1095685beae97897e0fe38db545ff9fdf7a9431cf1b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
